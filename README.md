# 
Hello! My name is Andrew Villapudua, a student at UC San Diego in La Jolla, California. I am a third year student (at the time of writing this) studying Math-CS. Recently, I have grown an interest for deep learning models which has invoked my study in this field. "How in the world can ChatGPT exist and respond well to such obscure prompts?" I ask myself. In this project, I lay a foundation of growth which I can later apply to future, more complex studies. More specifically, the foundation of convolutional neural networks and their role in image recognition. 

## Resources Used
- [Coursera Neural Networks and Deep Learning Course](https://www.coursera.org/learn/neural-networks-deep-learning)
- [Learn PyTorch for deep learning in a day. Literally.](https://www.youtube.com/watch?v=Z_ikDlimN6A&t=67946s&pp=ygUNbGVhcm4gcHl0b3JjaA%3D%3D) By Daniel Bourke
- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)
- ["Breast Histopathology Images."](https://www.kaggle.com/datasets/paultimothymooney/breast-histopathology-images) Dataset published by Paul Mooney on Kaggle

## The Data
 Also, I opted for a larger dataset as my model would yield the strongest as long as my neural network pairs well with it. The way this dataset works - or all image recognition datasets for that matter - will contain your input data, a [# of color channels, height, width] tensor that represents each individual image. This image will contain a label, in this case, it will classify it as apple, chicken, beans, etc. depending on the image given. I will show this in the following with this code snippit: 
